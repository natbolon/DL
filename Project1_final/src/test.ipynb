{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from dlc_practical_prologue import generate_pair_sets\n",
    "from generate_data import shuffle, normalize_data\n",
    "from graphics import generate_multiple_graphic_loss, generate_graphic_two_models\n",
    "from train import test_model_fc, test_model_separate, test_model_joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATTENTION: PLOTS WILL NOT BE SHOWN. \n",
      "ALL OF THEM ARE STOREM IN THE OUTPUT FOLDER\n",
      "Generate data\n",
      "Generate Variables\n"
     ]
    }
   ],
   "source": [
    "# Hide plots\n",
    "plt.ioff()\n",
    "print('ATTENTION: PLOTS WILL NOT BE SHOWN. \\nALL OF THEM ARE STOREM IN THE OUTPUT FOLDER')\n",
    "\n",
    "# set seed for reproducibility purposes\n",
    "seed(28)\n",
    "\n",
    "print('Generate data')\n",
    "train_input, train_target, train_classes, test_input, test_target, test_classes = generate_pair_sets(1000)\n",
    "\n",
    "# shuffle train set\n",
    "train_input, train_classes, train_target = shuffle(train_input, train_classes, train_target)\n",
    "\n",
    "# reshape\n",
    "train_input = train_input.reshape((train_input.size(0) * 2, 1, train_input.size(2), train_input.size(3)))\n",
    "test_input = test_input.reshape((test_input.size(0) * 2, 1, test_input.size(2), test_input.size(3)))\n",
    "\n",
    "train_classes = train_classes.view(-1,1)\n",
    "test_classes = test_classes.view(-1,1)\n",
    "\n",
    "# normalize\n",
    "normalize_data(train_input, test_input)\n",
    "\n",
    "# Generate variables\n",
    "print('Generate Variables')\n",
    "train_input, train_target, train_classes = Variable(train_input), Variable(train_target), Variable(train_classes)\n",
    "test_input, test_target, test_classes = Variable(test_input), Variable(test_target), Variable(test_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " --- Evaluate models for hyperparameter tunning ---\n",
      "Hyperparameter tunning for Model 1.1\n",
      "training Model 1.1 with lr=0.5\n",
      "\n",
      "Training: 100.0 - test error Net 5.00% 5/100\n",
      "Model with 70332 parameters\n",
      "Mean error: 5.00 Std deviation in error: nan\n",
      "         535167 function calls (517676 primitive calls) in 259.519 seconds\n",
      "\n",
      "   Ordered by: call count\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "   120000    0.288    0.000    0.288    0.000 tensor.py:428(<lambda>)\n",
      "    54407    0.092    0.000    0.092    0.000 module.py:521(__getattr__)\n",
      "    46092    0.017    0.000    0.017    0.000 {method 'values' of 'collections.OrderedDict' objects}\n",
      "    27610    0.010    0.000    0.010    0.000 {built-in method builtins.len}\n",
      "    25446    0.064    0.000    0.064    0.000 {built-in method torch._C._get_tracing_state}\n",
      "23046/5641    0.240    0.000  128.030    0.023 module.py:483(__call__)\n",
      "    16084    0.005    0.000    0.005    0.000 __init__.py:1404(_unwrap_optional)\n",
      "    15011    0.005    0.000    0.005    0.000 {method 'dim' of 'torch._C._TensorBase' objects}\n",
      "    10800    0.113    0.000    0.113    0.000 {method 'add_' of 'torch._C._TensorBase' objects}\n",
      "    10790    0.009    0.000    0.009    0.000 {method 'detach_' of 'torch._C._TensorBase' objects}\n",
      "    10790    0.047    0.000    0.047    0.000 {method 'zero_' of 'torch._C._TensorBase' objects}\n",
      "    10443    0.043    0.000    1.661    0.000 linear.py:65(forward)\n",
      "    10443    1.471    0.000    1.471    0.000 {built-in method addmm}\n",
      "    10443    2.982    0.000    2.982    0.000 {built-in method relu}\n",
      "    10443    0.030    0.000    3.012    0.000 functional.py:851(relu)\n",
      "    10443    0.048    0.000    1.602    0.000 functional.py:1336(linear)\n",
      "    10443    0.075    0.000    0.075    0.000 {method 't' of 'torch._C._TensorBase' objects}\n",
      "     7109    0.010    0.000    0.010    0.000 {method 'size' of 'torch._C._TensorBase' objects}\n",
      "     6968    0.079    0.000    0.079    0.000 {method 'view' of 'torch._C._TensorBase' objects}\n",
      "     6962   64.361    0.009   64.361    0.009 {built-in method conv2d}\n",
      "     6962    0.054    0.000   64.426    0.009 conv.py:317(forward)\n",
      "     5640    0.065    0.000    0.065    0.000 {method 'narrow' of 'torch._C._TensorBase' objects}\n",
      "     5226    0.004    0.000    0.004    0.000 {built-in method builtins.isinstance}\n",
      "     3484    0.019    0.000    0.019    0.000 {method 'item' of 'torch._C._TensorBase' objects}\n",
      "     3481   57.961    0.017   57.961    0.017 {built-in method torch._C._nn.max_pool2d_with_indices}\n",
      "     3481    0.063    0.000    0.063    0.000 {built-in method sigmoid}\n",
      "     3481    0.025    0.000   57.988    0.017 functional.py:404(max_pool2d_with_indices)\n",
      "     3481    0.024    0.000   58.011    0.017 functional.py:420(_max_pool2d)\n",
      "     3481    0.016    0.000   58.029    0.017 _jit_internal.py:122(fn)\n",
      "     3481    0.251    0.000  127.852    0.037 models.py:74(forward)\n",
      "     2402    0.043    0.000    0.043    0.000 {method 'max' of 'torch._C._TensorBase' objects}\n",
      "     2401    0.843    0.000    1.163    0.000 {built-in method builtins.sum}\n",
      "     2401    0.005    0.000    0.037    0.000 tensor.py:362(__rsub__)\n",
      "     2401    0.032    0.000    0.032    0.000 {built-in method rsub}\n",
      "     2400    0.001    0.000    0.001    0.000 {built-in method builtins.iter}\n",
      "     2400    0.021    0.000    0.032    0.000 tensor.py:414(__iter__)\n",
      "     2160    0.030    0.000    0.030    0.000 {built-in method torch._C._nn.nll_loss}\n",
      "     2160    0.004    0.000    0.059    0.000 functional.py:1272(log_softmax)\n",
      "     2160    0.010    0.000    0.045    0.000 functional.py:1735(nll_loss)\n",
      "     2160    0.006    0.000    0.110    0.000 functional.py:1924(cross_entropy)\n",
      "     2160    0.002    0.000    0.002    0.000 _reduction.py:8(get_enum)\n",
      "     2160    0.009    0.000    0.123    0.000 loss.py:901(forward)\n",
      "     2160    0.055    0.000    0.055    0.000 {method 'log_softmax' of 'torch._C._TensorBase' objects}\n",
      "     1808    0.001    0.000    0.001    0.000 {method 'append' of 'list' objects}\n",
      "     1401    0.000    0.000    0.000    0.000 {method 'getrandbits' of '_random.Random' objects}\n",
      "     1094    0.002    0.000    0.002    0.000 {method 'numel' of 'torch._C._TensorBase' objects}\n",
      "     1080    0.012    0.000  126.061    0.117 tensor.py:74(backward)\n",
      "     1080    0.014    0.000  126.049    0.117 __init__.py:38(backward)\n",
      "     1080    0.011    0.000    0.024    0.000 __init__.py:20(_make_grads)\n",
      "     1080    0.010    0.000    0.010    0.000 {built-in method ones_like}\n",
      "     1080  126.009    0.117  126.009    0.117 {method 'run_backward' of 'torch._C._EngineBase' objects}\n",
      "     1080    0.024    0.000    0.080    0.000 optimizer.py:157(zero_grad)\n",
      "     1080    0.059    0.000    0.173    0.000 sgd.py:71(step)\n",
      "      999    0.000    0.000    0.000    0.000 {method 'bit_length' of 'int' objects}\n",
      "      999    0.001    0.000    0.001    0.000 random.py:224(_randbelow)\n",
      "      366    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "      366    0.001    0.000    0.001    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "      366    0.000    0.000    0.000    0.000 threading.py:507(is_set)\n",
      "      366    0.000    0.000    0.001    0.000 threading.py:1038(_wait_for_tstate_lock)\n",
      "      366    0.001    0.000    0.002    0.000 threading.py:1080(is_alive)\n",
      "      366    0.012    0.000    0.012    0.000 socket.py:334(send)\n",
      "      366    0.000    0.000    0.000    0.000 iostream.py:93(_event_pipe)\n",
      "      366    0.002    0.000    0.016    0.000 iostream.py:195(schedule)\n",
      "      347    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "      246    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "      246    0.000    0.000    0.001    0.000 iostream.py:307(_is_master_process)\n",
      "      246    0.000    0.000    0.006    0.000 iostream.py:320(_schedule_flush)\n",
      "      246    0.001    0.000    0.019    0.000 iostream.py:382(write)\n",
      "      240    0.000    0.000    0.000    0.000 {built-in method time.time}\n",
      "      240    1.668    0.007   65.441    0.273 train.py:200(compute_nb_errors)\n",
      "      135    0.001    0.000    0.001    0.000 {method 'format' of 'str' objects}\n",
      "      124    0.000    0.000    0.001    0.000 module.py:537(__setattr__)\n",
      "      123    0.001    0.000    0.020    0.000 {built-in method builtins.print}\n",
      "       50    0.000    0.000    0.000    0.000 {built-in method builtins.id}\n",
      "       50    0.000    0.000    0.000    0.000 tensor.py:430(__hash__)\n",
      "     34/1    0.000    0.000    0.000    0.000 {built-in method _abc._abc_subclasscheck}\n",
      "     34/1    0.000    0.000    0.000    0.000 abc.py:141(__subclasscheck__)\n",
      "    34/14    0.000    0.000    0.000    0.000 module.py:938(named_modules)\n",
      "       32    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
      "       25    0.000    0.000    0.000    0.000 {built-in method math.sqrt}\n",
      "       24    0.000    0.000    0.000    0.000 {method 'items' of 'collections.OrderedDict' objects}\n",
      "       23    0.000    0.000    0.000    0.000 _collections_abc.py:392(__subclasshook__)\n",
      "       22    0.000    0.000    0.000    0.000 module.py:771(_named_members)\n",
      "       22    0.000    0.000    0.000    0.000 module.py:784(parameters)\n",
      "       22    0.000    0.000    0.000    0.000 module.py:808(named_parameters)\n",
      "       20    0.000    0.000    0.000    0.000 {built-in method torch._C.set_grad_enabled}\n",
      "       20    0.000    0.000    0.000    0.000 {built-in method torch._C.is_grad_enabled}\n",
      "       15    0.000    0.000    0.000    0.000 module.py:538(remove_from)\n",
      "       12    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "       12    0.000    0.000    0.000    0.000 module.py:829(<lambda>)\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\n",
      "       10    0.000    0.000    0.000    0.000 abc.py:137(__instancecheck__)\n",
      "       10    0.000    0.000    0.000    0.000 module.py:122(register_parameter)\n",
      "       10    0.000    0.000    0.000    0.000 parameter.py:23(__new__)\n",
      "       10    0.000    0.000    0.000    0.000 grad_mode.py:31(__enter__)\n",
      "       10    0.000    0.000    0.000    0.000 grad_mode.py:35(__exit__)\n",
      "       10    0.000    0.000    0.000    0.000 grad_mode.py:122(__init__)\n",
      "       10    0.000    0.000    0.000    0.000 utils.py:6(parse)\n",
      "       10    0.000    0.000    0.000    0.000 init.py:178(_calculate_fan_in_and_fan_out)\n",
      "       10    0.000    0.000    0.000    0.000 {method 'ndimension' of 'torch._C._TensorBase' objects}\n",
      "       10    0.001    0.000    0.001    0.000 {method 'uniform_' of 'torch._C._TensorBase' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method _make_subclass}\n",
      "        8    0.000    0.000    0.000    0.000 module.py:62(__init__)\n",
      "        7    0.000    0.000    0.000    0.000 _collections_abc.py:302(__subclasshook__)\n",
      "        5    0.000    0.000    0.000    0.000 {method 'setdefault' of 'dict' objects}\n",
      "        5    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\n",
      "        5    0.000    0.000    0.000    0.000 _collections_abc.py:72(_check_methods)\n",
      "        5    0.000    0.000    0.000    0.000 init.py:50(uniform_)\n",
      "        5    0.000    0.000    0.000    0.000 init.py:8(calculate_gain)\n",
      "        5    0.000    0.000    0.000    0.000 init.py:251(_calculate_correct_fan)\n",
      "        5    0.000    0.000    0.001    0.000 init.py:261(kaiming_uniform_)\n",
      "        4    0.000    0.000    0.000    0.000 tensor.py:376(__format__)\n",
      "        3    0.000    0.000    0.000    0.000 linear.py:58(reset_parameters)\n",
      "        3    0.000    0.000    0.001    0.000 linear.py:47(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 {method '__format__' of 'float' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method '__format__' of 'int' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.compile}\n",
      "        2    0.000    0.000  259.519  129.759 {built-in method builtins.exec}\n",
      "        2    0.000    0.000    0.000    0.000 ipstruct.py:125(__getattr__)\n",
      "        2    0.000    0.000    0.000    0.000 codeop.py:132(__call__)\n",
      "        2    0.000    0.000    0.000    0.000 interactiveshell.py:1258(user_global_ns)\n",
      "        2    0.000    0.000    0.000    0.000 hooks.py:142(__call__)\n",
      "        2    0.000    0.000    0.000    0.000 hooks.py:207(pre_run_code_hook)\n",
      "        2    0.000    0.000  259.519  129.759 interactiveshell.py:3230(run_code)\n",
      "        2    0.000    0.000    0.000    0.000 module.py:87(register_buffer)\n",
      "        2    0.000    0.000    0.001    0.000 conv.py:45(reset_parameters)\n",
      "        2    0.001    0.000    0.002    0.001 conv.py:17(__init__)\n",
      "        2    0.000    0.000    0.002    0.001 conv.py:307(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 loss.py:13(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 loss.py:22(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 loss.py:896(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'isdisjoint' of 'set' objects}\n",
      "        1    0.000    0.000    0.000    0.000 _collections_abc.py:252(__subclasshook__)\n",
      "        1    0.000    0.000    0.000    0.000 _collections_abc.py:271(__subclasshook__)\n",
      "        1    0.000    0.000    0.000    0.000 _collections_abc.py:349(__subclasshook__)\n",
      "        1    0.001    0.001    0.002    0.002 random.py:264(shuffle)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-5-dd23f9fe1f22>:20(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.003    0.003  259.519  259.519 <ipython-input-5-dd23f9fe1f22>:19(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method tensor}\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:32(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:174(add_param_group)\n",
      "        1    0.000    0.000    0.000    0.000 sgd.py:51(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 generate_data.py:44(<listcomp>)\n",
      "        1    0.001    0.001    0.004    0.004 generate_data.py:33(shuffle)\n",
      "        1    2.141    2.141  259.450  259.450 train.py:96(train_model_all)\n",
      "        1    0.002    0.002    0.002    0.002 train.py:386(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 train.py:418(<listcomp>)\n",
      "        1    0.003    0.003  259.516  259.516 train.py:364(test_model_joint)\n",
      "        1    0.000    0.000    0.003    0.003 models.py:65(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'type' of 'torch._C._TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'mean' of 'torch._C._TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'std' of 'torch._C._TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'sum' of 'torch._C._TensorBase' objects}\n",
      "\n",
      "\n",
      "training Model 1.1 with lr=1e-1\n",
      "\n",
      "training Model 1.1 with lr=1e-2\n",
      "\n",
      "training Model 1.1 with lr=1e-3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define common parameters\n",
    "\n",
    "pr=cProfile.Profile()\n",
    "\n",
    "r = 1 # number of runs\n",
    "v = 3  # verbose\n",
    "\n",
    "\n",
    "print('\\n --- Evaluate models for hyperparameter tunning ---')\n",
    "# Hyperparameter tunning for model 1.1\n",
    "print('Hyperparameter tunning for Model 1.1')\n",
    "e = 500\n",
    "\n",
    "\n",
    "print('training Model 1.1 with lr=0.5\\n')\n",
    "e31=120\n",
    "l_rate = 0.5\n",
    "pr.enable()\n",
    "data31_07 = test_model_joint(train_input, train_classes, train_target, runs=r, epochs=e31, lr=l_rate, w1=0.7, w2=0.3, verbose=v)\n",
    "pr.disable()\n",
    "pr.print_stats(sort=\"calls\")\n",
    "\n",
    "\n",
    "print('training Model 1.1 with lr=1e-1\\n')\n",
    "#data11_1 = test_model_fc(train_input, train_classes, train_target, runs=r, epochs=e, l_rate=1e-1, verbose=v)\n",
    "print('training Model 1.1 with lr=1e-2\\n')\n",
    "#data11_2 = test_model_fc(train_input, train_classes, train_target, runs=r, epochs=e, l_rate=1e-2, verbose=v)\n",
    "print('training Model 1.1 with lr=1e-3\\n')\n",
    "#data11_3 = test_model_fc(train_input, train_classes, train_target, runs=r, epochs=e, l_rate=1e-3, verbose=v)\n",
    "\n",
    "\n",
    "# Generate graphics\n",
    "#legend = ['lr=0.5', 'lr=1e-1','lr=1e-2','lr=1e-3']\n",
    "#g_names = {'file_name': 'train_m11_hyperparameters_epochs500', 'title': 'Validation Error for target prediction', 'y_axis': 'Errors' , 'legend': legend}\n",
    "\n",
    "#m = [data11_4, data11_1, data11_2, data11_3]\n",
    "#generate_multiple_graphic_loss([mod['error_test'] for mod in m], g_names, save=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Hyperparameter tunning for model 2.1\n",
    "print('Hyperparameter tunning for Model 2.1')\n",
    "e21 = 50\n",
    "\n",
    "print('training Model 2.1 with lr(1)=1 and lr(2)=0.5\\n')\n",
    "data21_1 = test_model_separate(train_input, train_classes, train_target, runs=r, epochs=e21, epochs2=15, version=0, lr=1, verbose=v)\n",
    "print('training Model 2.1 with lr(1)=0.5 and lr(2)=0.5\\n')\n",
    "data21_2 = test_model_separate(train_input, train_classes, train_target, runs=r, epochs=e21, epochs2=15, version=0, lr=0.5, verbose=v)\n",
    "print('training Model 2.1 with lr(1)=0.1 and lr(2)=0.5\\n')\n",
    "data21_3 = test_model_separate(train_input, train_classes, train_target, runs=r, epochs=e21, epochs2=15, version=0, lr=0.1, verbose=v)\n",
    "print('training Model 2.1 with lr(1)=1e-2 and lr(2)=0.5\\n')\n",
    "data21_4 = test_model_separate(train_input, train_classes, train_target, runs=r, epochs=e21, epochs2=15, version=0, lr=1e-2, verbose=v)\n",
    "print('training Model 2.1 with lr(1)=0.5 and lr(2)=0.5\\n')\n",
    "data21_5 = test_model_separate(train_input, train_classes, train_target, runs=10, epochs=20, epochs2=25, version=0, lr=0.5, verbose=v)\n",
    "print('training Model 2.1 with lr(1)=0.5 and lr(2)=0.1\\n')\n",
    "data21_6 = test_model_separate(train_input, train_classes, train_target, runs=10, epochs=20, epochs2=25, version=0, lr=0.5,lr2=0.1, verbose=v)\n",
    "\n",
    "# Generate graphic\n",
    "m = [data21_1, data21_2, data21_3 ,data21_4]\n",
    "mm = [data21_5, data21_6]\n",
    "legend = ['lr=1','lr=0.5','lr=1e-1', 'lr=1e-2']\n",
    "legend2 = ['lr=0.5','lr=1e-1']\n",
    "\n",
    "g_names = {'file_name': 'train_m21_hyperparameters_error_m1_rows', 'title': ['Validation Error for class prediction', 'Validation Error for target prediction'],\n",
    "           'y_axis': 'Errors' , 'legend': legend, 'legend_2': legend2}\n",
    "generate_graphic_two_models([mod['error_test_m1'] for mod in m],[mod['error_test_m2'] for mod in mm], g_names, version='rows', save=True)\n",
    "\n",
    "# Weight tunning for model 3.1\n",
    "print('Weight tunning for Model 3.1')\n",
    "e31=120\n",
    "l_rate = 0.5\n",
    "print('\\ntraining Model 3.1 with w1=0.7 and w2=0.3\\n')\n",
    "data31_07 = test_model_joint(train_input, train_classes, train_target, runs=r, epochs=e31, lr=l_rate, w1=0.7, w2=0.3, verbose=v)\n",
    "print('\\ntraining Model 3.1 with w1=0.3 and w2=0.7\\n')\n",
    "data31_03 = test_model_joint(train_input, train_classes, train_target, runs=r, epochs=e31, lr=l_rate, w1=0.3, w2=0.7, verbose=v)\n",
    "print('\\ntraining Model 3.1 with w1=0.5 and w2=0.5\\n')\n",
    "data31_05 = test_model_joint(train_input, train_classes, train_target, runs=r, epochs=e31, lr=l_rate, w1=0.5, w2=0.5, verbose=v)\n",
    "\n",
    "\n",
    "# Generate graphic\n",
    "m = [data31_07, data31_03, data31_05]\n",
    "legend = ['w1=0.7, w2=0.3', 'w1=0.3, w2=0.7', 'w1=w2=0.5']\n",
    "g_names = {'file_name': 'train_m31_weights', 'title': 'Validation Error for target prediction', 'y_axis': 'Errors' , 'legend': legend}\n",
    "generate_multiple_graphic_loss([mod['error_test_m2'] for mod in m], g_names, save=True)\n",
    "\n",
    "### EVALUATE THE DIFFERENT MODELS IN THE TEST SET\n",
    "print('\\n----Evaluate models with TEST set----')\n",
    "\n",
    "print('\\nEvaluate model 1.1')\n",
    "# evaluate model 1.1 in TEST set\n",
    "d_model_11 = test_model_fc(train_input, train_classes, train_target,test_i_org=test_input, test_c_org=test_classes, test_t_org=test_target, runs=r, epochs=220, l_rate=1e-2, verbose=3)\n",
    "\n",
    "print('\\nEvaluate model 1.2')\n",
    "# evaluate model 1.2 in TEST set\n",
    "d_model_12 = test_model_joint(train_input, train_classes, train_target, test_input, test_classes, test_target, runs=r, epochs=35, w1=0, lr=0.1, verbose=3)\n",
    "\n",
    "print('\\nEvaluate model 2.1')\n",
    "# evaluate model 2.1 in TEST set\n",
    "d_model_21 = test_model_separate(train_input, train_classes, train_target, test_input, test_classes, test_target, runs=r, epochs=30, epochs2=25, version=0, lr=0.1, verbose=2)\n",
    "\n",
    "print('\\nEvaluate model 2.2')\n",
    "# evaluate model 2.2 in TEST set\n",
    "d_model_22 = test_model_separate(train_input, train_classes, train_target, test_input, test_classes, test_target, runs=r, epochs=30, epochs2=25, version=1, lr=0.1, verbose=2)\n",
    "\n",
    "print('\\nEvaluate model 3.1')\n",
    "# evaluate model 3.1 in TEST set\n",
    "d_model_31 = test_model_joint(train_input, train_classes, train_target, test_input, test_classes, test_target, runs=r, epochs=55, lr=0.5, verbose=2, w1=0.7, w2=0.3)\n",
    "\n",
    "# generate graphic to compare single models in terms of errors along epochs and time\n",
    "m = [d_model_11, d_model_12, d_model_31]\n",
    "l = ['Model 1.1','Model 1.2', 'Model 3.1']\n",
    "\n",
    "g_names = {'file_name': 'comparison_single_models', 'title': 'Test Error for target prediction', 'y_axis': 'Errors' , 'legend': l}\n",
    "generate_multiple_graphic_loss([ d_model_11['error_test'], d_model_12['error_test_m2'], d_model_31['error_test_m2']], g_names, [mod['time'] for mod in m],version='rows',save=True)\n",
    "\n",
    "print('DONE!')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
