{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import dlc_practical_prologue as prologue\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt #To remove (use matplotlib)\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_image(im):        #To remove (use matplotlib)\n",
    "    plt.imshow(im, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(N, normalize):\n",
    "    train_input, train_target, train_classes, test_input, test_target, test_classes = prologue.generate_pair_sets(N)\n",
    "    if (normalize):\n",
    "        train_input = (train_input - train_input.mean())/train_input.std()\n",
    "        test_input = (test_input - train_input.mean())/train_input.std()\n",
    "    return (train_input, train_target, train_classes, test_input, test_target, test_classes)\n",
    "\n",
    "def make_one_hot(vector):\n",
    "    one_hot = torch.zeros(( vector.size(0) , int(vector.max())+1 ))\n",
    "    for i in range(0, vector.size(0)):\n",
    "        one_hot[i, vector[i]] = 1\n",
    "    return one_hot\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 2, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "N = 1000 #num\n",
    "train_input, train_target, train_classes, test_input, test_target, test_classes = import_data(N, True)\n",
    "train_target_one_hot = make_one_hot(train_target)\n",
    "test_target_one_hot = make_one_hot(test_target)\n",
    "train_classes_one_hot = make_one_hot(train_classes[:,0])\n",
    "test_classes_one_hot = make_one_hot(test_classes[:,0])\n",
    "\n",
    "print(train_input.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_image(train_input[364,0,:,:])\n",
    "\n",
    "#blub = make_one_hot(train_target)\n",
    "#blib = make_one_hot(train_classes[:,0])\n",
    "\n",
    "#print(blub)\n",
    "#print(blib)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Images and doing substraction (Aborter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "    \n",
    "def compute_nb_errors(model, data_input, data_target):\n",
    "    mini_batch_size = 100\n",
    "    error = 0\n",
    "    for b in range(0, data_input.size(0), mini_batch_size):\n",
    "        output = model(data_input[b : b + mini_batch_size])\n",
    "        _, output = torch.max(output, dim = 1)\n",
    "        \n",
    "        if data_target.dim() == 2: #Switch from one hot to normal\n",
    "            _, target = torch.max(data_target[b : b + mini_batch_size], dim = 1)\n",
    "        else: \n",
    "            target = data_target[b : b + mini_batch_size]\n",
    "            \n",
    "        error += int( (output - target).abs().sum())\n",
    "    return( error )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same network as Natalie: no auxiliary losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class No_aux_losses(nn.Module):\n",
    "    def __init__(self, nb_hidden):\n",
    "        super(No_aux_losses, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1*2, 32*2, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32*2, 64*2, kernel_size=5)\n",
    "        self.fcA1 = nn.Linear(1024*2, nb_hidden*2)\n",
    "        self.fcA2 = nn.Linear(nb_hidden*2, 2*10)\n",
    "        self.fcB1 = nn.Linear(20, 100)\n",
    "        self.fcB2 = nn.Linear(100,200)\n",
    "        self.fcB3 = nn.Linear(200, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=2, stride=1))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2, stride=1))\n",
    "        x = F.relu(self.fcA1(x.view(-1, 1024*2)))\n",
    "        x = self.fcA2(x)\n",
    "        x = F.relu(self.fcB1(x))\n",
    "        x = F.relu(self.fcB2(x))\n",
    "        x = self.fcB3(x)\n",
    "        return x    \n",
    "    \n",
    "def train_model_no_aux_losses(model, train_input, train_target, epochs=25, \\\n",
    "                mini_batch_size=100, lr=1e-3, criterion=None, optimizer=None, verbose=2, return_rate=False):\n",
    "    \n",
    "    print('Training network with no auxiliary losses')\n",
    "    \n",
    "    # use MSE loss by default\n",
    "    if not criterion:\n",
    "        criterion = nn.MSELoss()\n",
    "    \n",
    "    # use SGD by default\n",
    "    if not optimizer:\n",
    "        optimizer = optim.SGD(model.parameters(), lr = lr)\n",
    "\n",
    "    if return_rate:\n",
    "        nb_error = torch.zeros((1, epochs))\n",
    "        loss_list = torch.zeros((1, epochs))\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        sum_loss = 0\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            \n",
    "            #print(train_input.narrow(0, b, mini_batch_size).size())\n",
    "            #print(output.size())\n",
    "            #print(train_target.narrow(0, b, mini_batch_size).size())\n",
    "            \n",
    "            loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            sum_loss = sum_loss + loss.item()\n",
    "            with torch.no_grad():\n",
    "                optimizer.step()\n",
    "                \n",
    "            if return_rate:\n",
    "                nb_error[0,e] = compute_nb_errors(model, train_input, train_target)\n",
    "                loss_list[0,e] = sum_loss\n",
    "                \n",
    "            #for p in model.parameters():\n",
    "            #    p.data.sub_(lr * p.grad.data)\n",
    "        \n",
    "        if verbose == 0: print('Epoch: {}, loss: {:0.2f}'.format(e, sum_loss))\n",
    "        elif verbose == 1 and e%5 == 0: print(e, sum_loss)\n",
    "            \n",
    "    if return_rate:\n",
    "        return((nb_error, loss_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training network with no auxiliary losses\n",
      "0 4.50802144408226\n",
      "577\n",
      "445\n"
     ]
    }
   ],
   "source": [
    "model_no_aux_losses = No_aux_losses(200)\n",
    "train_model_no_aux_losses(model_no_aux_losses, train_input, train_target_one_hot, verbose=1,\\\n",
    "                          epochs = 4)\n",
    "\n",
    "out = model_no_aux_losses(test_input)\n",
    "\n",
    "print(compute_nb_errors(model_no_aux_losses, train_input, train_target))\n",
    "print(compute_nb_errors(model_no_aux_losses, test_input, test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model_no_aux_losses.fcA1.weight)\n",
    "#print(model_no_aux_losses.fcA1.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training network with no auxiliary losses\n",
      "0 4.836097031831741\n",
      "5 4.270540118217468\n"
     ]
    }
   ],
   "source": [
    "model_no_aux_losses = No_aux_losses(200)\n",
    "nb_error, loss_list = train_model_no_aux_losses(model_no_aux_losses, train_input, train_target_one_hot, verbose=1,\\\n",
    "                                    epochs = 70, return_rate=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Plot kinda nicely\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Loss function\")\n",
    "plt.plot(np.arange(0,loss_list.size(1)) , loss_list[0,:].numpy())\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(np.arange(0,nb_error.size(1)) , nb_error[0,:].numpy())\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Number of test of errors\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "A = torch.tensor([[1,2],[4,5]])\n",
    "B = torch.tensor([1,2])\n",
    "\n",
    "print(B.dim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
